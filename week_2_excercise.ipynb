{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\"\\n      dir=\"ltr\"\\n      xmlns:fb=\"http://www.facebook.com/2008/fbml\"\\n      xmlns:og=\"http://opengraphprotocol.org/schema/\">\\n\\n    <head prefix=\"og: http://ogp.me/ns# flixstertomatoes: http://ogp.me/ns/apps/flixstertomatoes#\">\\n        \\n            <script src=\"/assets/piz'\n"
     ]
    }
   ],
   "source": [
    "# First, import the libraries you need for reading in web content. Use the model in \"WebScraping.ipynb.\" \n",
    "# Set the URL to a website of interest for your work: this can be anything, but will work best if it's a static site \n",
    "# (not a social media hashtag, etc.)\n",
    "\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "\n",
    "url = 'https://www.rottentomatoes.com/m/shang_chi_and_the_legend_of_the_ten_rings'\n",
    "\n",
    "response = urllib.request.urlopen(url)\n",
    "webContent = response.read()\n",
    "\n",
    "print(webContent[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, save the website you are interested in as a file. \n",
    "# Name that file appropriately to the content - for instance, something like \"reviewarchive.html\" would make sense if you are pulling reviews of a movie or book. \n",
    "# After you run it, check that the file looks like it has the content you need. \n",
    "# If it doesn't, try to figure out what went wrong.\n",
    "\n",
    "url = 'https://www.rottentomatoes.com/m/shang_chi_and_the_legend_of_the_ten_rings'\n",
    "\n",
    "response = urllib.request.urlopen(url)\n",
    "webContent = response.read()\n",
    "\n",
    "f = open('shangchireview.html', 'wb')\n",
    "f.write(webContent)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third, append another page of connected content: you'll need to use a modified version of the previous code, \n",
    "# changing the URL, and using \"append binary\" to add to the file.\n",
    "\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "\n",
    "url = 'https://editorial.rottentomatoes.com/article/shang-chi-first-reviews-one-of-the-mcus-most-spectacular-origin-stories/'\n",
    "response = urllib.request.urlopen(url)\n",
    "webContent = response.read()\n",
    "\n",
    "f = open('shangchireview.html', 'ab')\n",
    "f.write(webContent)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\"\n",
      "      dir=\"ltr\"\n",
      "      xmlns:fb=\"http://www.facebook.com/2008/fbml\"\n",
      "      xmlns:og=\"http://opengraphprotocol.org/schema/\">\n",
      "\n",
      "    <head prefix=\"og: http://ogp.me/ns# flixstertomatoes: http://ogp.me/ns/apps/flixstertomatoes#\">\n",
      "        \n",
      "            <script src=\"/assets/piz\n"
     ]
    }
   ],
   "source": [
    "# Next, pull in the contents of the new file (with multiple pages of HTML) using our text file reading example from week one as a model.\n",
    "# Store those contents in a new variable, named appropriately to the contents.\n",
    "# Print a subset of the output to confirm the import was successful.\n",
    "\n",
    "f = open('shangchireview.html','r')\n",
    "reviews = f.read()\n",
    "print(reviews[0:300])\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences of Marvel: 63\n",
      "['<!DOCTYPE', 'html>\\n<html', 'lang=\"en\"\\n', '', '', '', '', '', 'dir=\"ltr\"\\n', '', '', '', '', '', 'xmlns:fb=\"http://www.facebook.com/2008/fbml\"\\n', '', '', '', '', '', 'xmlns:og=\"http://opengraphprotocol.org/schema/\">\\n\\n', '', '', '', '<head', 'prefix=\"og:', 'http://ogp.me/ns#', 'flixstertomatoes:', 'http://ogp.me/ns/apps/flixstertomatoes#\">\\n', '', '', '', '', '', '', '', '\\n', '', '', '', '', '', '', '', '', '', '', '', '<script', 'src=\"/assets/pizza-pie/javascripts/bundles/roma/rt-common.js?single\"></script>\\n', '', '', '', '', '', '', '', '\\n', '', '', '', '', '', '', '', '<!--', 'salt=lay-def-02-juRm', '-->\\n', '', '', '', '', '', '', '', '<meta', 'http-equiv=\"Content-Type\"', 'content=\"text/html;', 'charset=utf-8\"', '/>\\n', '', '', '', '', '', '', '', '<meta', 'http-equiv=\"x-ua-compatible\"', 'content=\"ie=edge\">\\n', '', '', '', '', '', '', '', '<meta', 'name=\"viewport\"', 'content=\"width=device-width,']\n",
      "Index of Marvel: 753\n",
      "Slice from index 700 to 800: es</title>\n",
      "        <meta name=\"description\" content=\"Marvel Studios' \"Shang-Chi and The Legend of Th\n",
      "Character name more than studio name.\n"
     ]
    }
   ],
   "source": [
    "# Finally, use the examples in \"Conditionals.ipynb\" and \"PlayingWithStrings.ipynb\" to run \n",
    "# at least five simple data analyses commands on your content and print the results with an explanatory statement,\n",
    "# as in the examples. Here's a few suggestions to try, but feel free to expand on them.\n",
    "\n",
    "# 1. Count and print the occurences of a key word\n",
    "\n",
    "f = open('shangchireview.html','r')\n",
    "reviews = f.read()\n",
    "print(\"Occurences of Marvel: \" + str(reviews.count(\"Marvel\")))\n",
    "\n",
    "# 2. Split your dataset into strings based on word spacing, and print some of the words to view the set\n",
    "\n",
    "split_string = reviews.split(\" \")\n",
    "print(split_string[0:100])\n",
    "\n",
    "# 3. Locate the index of a word of interest, then print the phrase surrounding it\n",
    "\n",
    "print(\"Index of Marvel: \" + str(reviews.index(\"Marvel\")))\n",
    "print(\"Slice from index 700 to 800: \" + reviews[700:800])\n",
    "\n",
    "# 4. Compare the number of occurences of two significant words, such as character names, using a conditional statement.\n",
    "# The printed statement should be different for each outcome,\n",
    "# and handle the case where the numbers are the same (try using if, elif, and else)\n",
    "\n",
    "character = \"Shang-Chi\" \n",
    "studio = \"Marvel\"\n",
    "\n",
    "character = reviews.count(\"Shang-Chi\")\n",
    "studio = reviews.count(\"Marvel\") \n",
    "\n",
    "if studio > character:\n",
    "    print(\"Studio name more than character name\")\n",
    "elif studio < character:\n",
    "    print(\"Character name more than studio name.\")\n",
    "else: \n",
    "    print(\"Studio and character names equal.\")\n",
    "\n",
    "# 5. Search for a word and use \"in\" to print true if the word is found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python388jvsc74a57bd081406bfb4a0df296520439dbeeb6cb234f05909e99c5846f7ab3626eb610afcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}